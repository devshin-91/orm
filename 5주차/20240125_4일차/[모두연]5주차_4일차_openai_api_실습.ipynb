{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_n2aIGBDWIv",
        "outputId": "138f7af6-868d-479f-d665-aa275ec05e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m986.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.9.0 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI  # OpenAI 모듈 불러오기\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "client = OpenAI(api_key='본인 secret key')  # 사용자의 API 키로 대체해야 함\n",
        "\n",
        "# ChatGPT를 사용한 텍스트 생성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Hello World!\"}]\n",
        ")\n",
        "# API 응답에서 마지막 메시지의 내용을 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrahX9HPDeiY",
        "outputId": "c9f33497-8c47-47cf-ad6c-c14045bf4738"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# ChatGPT를 사용한 텍스트 생성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Translate the following English text to French: 'Hello, how are you?'\"}]\n",
        ")\n",
        "\n",
        "#응답 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOERtgxCPvBV",
        "outputId": "03a0242a-2e30-466f-994b-c368b34365db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bonjour, comment ça va?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# ChatGPT를 사용한 텍스트 생성 요청\n",
        "response = client.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages = [{\"role\" : \"user\", \"content\" : \"Translate the following English text to Korean: 'Hello, how are you?'\"}]\n",
        ")\n",
        "\n",
        "#응답 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPCzt3kEPylZ",
        "outputId": "29121a10-661f-41f2-d997-5763b6645f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요, 어떻게 지내세요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = [{\"role\" : \"user\", \"content\" : \"Translate the following korean text to English: 안녕하세요 오늘 날씨가 좋네요. 햇살이 맑아요\"}],\n",
        "        max_tokens=10,\n",
        "        temperature=0.7,\n",
        "        top_p=0.8,\n",
        "        frequency_penalty=0.2\n",
        "    )\n",
        "    print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "id": "n-QDZpjhP-fX",
        "outputId": "c6721d49-6393-4a52-c40d-b6d319574778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n",
            "Hello, today's weather is nice. The sunlight\n",
            "Hello, today the weather is nice. The sunlight\n",
            "Hello, today's weather is nice. The sunlight\n",
            "Hello, today the weather is good. The sunlight\n",
            "Hello, today the weather is good. The sunlight\n",
            "Hello, the weather is nice today. The sunlight\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPStatusError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# thrown on 4xx and 5xx status code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPStatusError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-82b9bd8c3fe6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"Translate the following korean text to English: 안녕하세요 오늘 날씨가 좋네요. 햇살이 맑아요\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 648\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[0;32m-> 1179\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 868\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    869\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    945\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# different thread if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         return self._request(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_chatbot(messages):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\", messages = messages\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "prompt_role = \"너는 블로그 전문가, 파워블로그처럼 글을 써야해.\\\n",
        "                개발자의 직업관에 대한 글을 써야하고,\\\n",
        "                그리고 취업을 준비하는 20대 독자들에게 잘 보일수 있도록 글을 써야되\\\n",
        "                SEO최적화된 글을 써야되\""
      ],
      "metadata": {
        "id": "eabdxSgrRDgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "def assist_blogger(\n",
        "    facts: List[str], tone: str, length_words: int, style: str\n",
        "):\n",
        "    facts = \", \".join(facts)\n",
        "    prompt_role = \"너는 블로그 전문가고, 파워블로그처럼 글을 써야해\"\n",
        "    prompt = f\"{prompt_role} \\\n",
        "            FACTS: {facts} \\\n",
        "            TONE: {tone} \\\n",
        "            LEGNTH: {length_words} words \\\n",
        "            STYLE: {style}\"\n",
        "    return ask_chatbot([{\"role\": \"user\", \"content\": prompt}])"
      ],
      "metadata": {
        "id": "UsbW2ezYRHUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    assist_blogger(\n",
        "        [\"대학 진학 이후의 개발자의 삶은?\"], \"informal\", 100, \"blogpost\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdWgEmDXRLSW",
        "outputId": "315b94b1-21cb-43bd-b122-7eb0cb4efa89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요! 블로그 전문가로서 개발자들을 위한 정보를 제공하는 나날블로거입니다. 오늘은 대학 진학 이후의 개발자의 삶에 대해 이야기해보고자 합니다.\n",
            "\n",
            "대학을 졸업하고 진로를 개발자로 선택한 당신, 혹은 개발자로 성공적으로 일하고 있는 분들은 어떤 삶을 살고 있나요? 사실, 개발자의 삶은 사람마다 다를 수 있습니다. 하지만 몇 가지 공통된 팩트들이 있습니다.\n",
            "\n",
            "첫째, 개발자의 일상은 항상 도전적입니다. 새로운 기술과 언어의 변화에 대응하고, 업계의 요구사항을 따라가기 위해 공부하고 발전해야 합니다. 물론 이것이 개발자의 장점이기도 하죠. 항상 새로움을 추구하는 개발자는 혁신과 성장에 더 적극적으로 기여할 수 있습니다.\n",
            "\n",
            "둘째, 협업은 개발자의 삶에서 중요한 부분을 차지합니다. 개발은 단순히 코드 작성만으로는 이루어질 수 없는 작업입니다. 다른 팀원들과의 원활한 소통과 협력이 필요합니다. 기술적인 문제를 해결하면서도 다양한 의견을 수렴하고 존중하는 능력이 필수입니다.\n",
            "\n",
            "셋째, 자기 계발은 개발자의 일상에 꼭 필요한 부분입니다. 기술의 변화 속에서 자신의 전문성을 유지하고 발전시키기 위해서는 지속적인 공부와 학습이 필요합니다. 또한, 개발자의 네트워크와 커뮤니티에 참여하여 다른 사람들과 교류하고 지식을 공유하는 것도 중요합니다.\n",
            "\n",
            "마지막으로, 개발자의 삶은 도전과 성취감으로 가득합니다. 어려운 문제를 해결하고 완성된 소프트웨어를 만들어내는 과정은 개발자에게 큰 성취감을 줍니다. 또한, 자신이 만든 프로그램이 다양한 사람들에게 도움이 되는 것을 보고 자부심을 느낄 수 있습니다.\n",
            "\n",
            "대학 진학 이후의 개발자의 삶은 항상 변화하고 진화하는 것이 필요하지만, 계속해서 도전하고 발전할 준비가 되어 있다면 블로그 전문가인 나날블로거는 자신있게 말할 수 있습니다. 어떠한 삶을 선택하던, 언제나 좋은 결과를 기대할 수 있도록 노력해봅시다. 행운을 빕니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첨부된 파일을 읽고 작은 부분으로 나누기 위한 코드입니다.\n",
        "\n",
        "# 파일 경로 설정\n",
        "file_path = '/content/English_But_what_is_a_neural_network____Chapter_1_Deep_learning_DownSub.com.txt'\n",
        "\n",
        "# 파일을 읽어서 내용을 저장\n",
        "with open(file_path, 'r') as file:\n",
        "    transcript = file.read()\n",
        "\n",
        "# 텍스트를 나눌 최대 길이 설정 (토큰 수가 아닌 문자 수 기준)\n",
        "max_length = 5000  # 각 부분의 최대 길이 (문자 수)\n",
        "\n",
        "# 텍스트를 작은 부분으로 나누는 함수\n",
        "def split_into_parts(text, length):\n",
        "    return [text[i:i+length] for i in range(0, len(text), length)]\n",
        "\n",
        "# 텍스트를 여러 부분으로 나눔\n",
        "parts = split_into_parts(transcript, max_length)\n",
        "\n",
        "# 나누어진 부분들의 수와 첫 부분의 내용 일부를 출력\n",
        "num_parts = len(parts)\n",
        "first_part_preview = parts[0][:500]  # 첫 부분의 처음 500자\n",
        "\n",
        "num_parts, first_part_preview"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDo0fMcEVUFa",
        "outputId": "f799c99b-38c0-4f1e-b6c8-33a44a4fc0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " \"This is a 3. It's sloppily written and rendered at an extremely low resolution of 28x28 pixels,\\n\\nbut your brain has no trouble recognizing it as a 3. And I want you to take a moment\\n\\nto appreciate how crazy it is that brains can do this so effortlessly. I mean, this,\\n\\nthis and this are also recognizable as 3s, even though the specific values of each pixel\\n\\nis very different from one image to the next. The particular light-sensitive cells in your\\n\\neye that are firing when you see this 3 are very \")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 부분만 사용\n",
        "first_part = parts[0]\n",
        "\n",
        "# 첫 번째 부분에 대한 번역 요청\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages = [\n",
        "        {\"role\" : \"system\", \"content\" : \"너는 유튜브를 영어에서 한국어로 번역하는 번역가이자, 요약을 잘하는 역할을 할꺼야\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"업로드한 파일을 한국어로 변역해줘\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"한국어로 번역한 내용을 요약해\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : first_part}\n",
        "      ],\n",
        ")\n",
        "\n",
        "# 번역 결과 출력\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wADFtcOEVjmR",
        "outputId": "1b65819f-d626-4ec2-b969-185f09c10f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이것은 3이에요. 불완전하게 쓰여있고, 해상도도 28x28 픽셀로 매우 낮지만, 당신의 뇌는 이것을 3으로 인식하는데 어려움이 없어요. 그리고 이러한 것도 3으로 인식되는데, 각 픽셀의 특정 값은 서로 매우 다릅니다. 이 3을 보면 눈에서 빛을 감지하는 특정한 세포가 이것을 보면 활성화되는 것과, 저것을 보면 활성화되는 것은 매우 다르지만, 당신의 비정상적으로 똑똑한 시각 피질 안에서 이것들이 같은 아이디어를 나타낸다고 인식하는 것입니다. 그리고 동시에 다른 이미지들을 자체적으로 다른 아이디어로 인식합니다. 그러나 내게 이 28x28 그리드를 입력으로 받아서 0부터 10 사이의 하나의 숫자를 출력하는 프로그램을 작성해달라고 말하면, 일은 헐렁미치지만 거대한 과업으로 어려워집니다. 돌거라면 기계학습과 신경망이 현재와 미래에 얼마나 관련되고 중요한지 설득할 필요가 거의 없지만, 여기서는 당신이 실제로 신경망이 무엇인지, 어떤 배경지식도 없다고 전제하고 그것이 하는 일을 시각적으로 도움이 될 만큼 이해하고, 좀 더 추상적으로, '신경망이 배운다'라는 문구를 읽거나 들을 때 그것이 무슨 의미인지 아는 데 도움이 되기를 바랍니다. 이 비디오는 주로 그 구조적인 요소에 집중되어 있으며, 그 다음 비디오에서는 학습에 대해 다룰 겁니다. 우리는 손글씨 숫자를 인식할 수 있는 신경망을 구성할 거에요. 이는 주제를 소개하는데 있어서 어느 정도 고전적인 예제입니다. 그리고 저는 이를 그대로 따를 때 기분이 좋아요. 왜냐하면 두 비디오가 끝나면 더 자세히 알아볼 수 있는 몇 가지 좋은 자료와 이것을 할 수 있도록 코드를 다운로드 받을 수 있는 곳을 안내해주고 싶기 때문입니다. 신경망에는 많은 변형이 있으며, 최근 몇 년 동안 연구에 많은 관심이 집중되어 왔습니다. 하지만 이 두 개의 입문 비디오에서는 가능한 가장 간단하고 기본적인 형태인 플레인 바닐라 형태만 살펴볼 거에요. 이는 이를 통해 이해할 수 있는 다른 더 강력한 현대적인 형태 중 어떤 것이든 이전에 필요한 사전 조건입니다. 그리고 미리 말씀드리지만, 이 가장 간단한 형태로도 손글씨 숫자를 인식할 수 있으며, 컴퓨터의 입장에서는 꽤 멋진 일입니다. 동시에 우리가 가지고 있는 희망 중 일부에는 적합하지 못하다는 점도 보게 될 거에요. 이름이 들어내린대로, 신경망은 뇌에서 영감을 받았지만, 이를 구체화해보죠. 신경세포가 무엇이고, 어떤 의미에서 이들이 연결되어 있는 걸까요? 현재 내가 '신경세포'라 말할 때 당신이 떠올리는 것은 단지 0과 1 사이의 숫자를 저장하는 것, 즉 그 이상이 아니에요. 예를 들면, 네트워크는 입력 이미지의 각각 28x28 픽셀에 해당하는 신경세포들로 시작해요. 그러니까 전체적으로는 784개의 신경세포가 있죠. 각각은 해당 픽셀의 회색조 값을 나타내는 숫자를 저장하며, 검은색 픽셀에 대해 0부터 흰색 픽셀에 대해 1까지 범위에 해당하는 값입니다. 이 신경세포 내부의 숫자는 그 활성화라고 불리며, 당신이 상상하는 그림은 각 신경세포가 활성화 수치가 높을 때 켜져있다는 것입니다. 이 784개의 신경세포는 우리 네트워크의 첫 번째 레이어를 구성한다고 할 수 있어요. 이제 마지막 레이어로 넘어가볼게요. 이는 10개의 신경세포를 가지고 있으며, 각각은 하나의 숫자를 나타냅니다. 이 신경세포들의 활성화 역시 0과 1 사이의 숫자로, 시스템이 어떤 이미지가 어떤 숫자에 해당하는지에 대해 얼마나 생각하는지를 나타냅니다. 그리고 \"은신된\" 몇 개의 레이어들도 있어요. 당장은 어떻게 이 문제를 처리해야 할지 모르므로 거대한 의문이 될 거에요. 이 네트워크에서는 두 개의 은신 레이어를 선택했고, 각각에 16개의 신경세포가 있다는 것, 솔직히 말씀드리면 이는 다소 임의적인 선택입니다. 솔직하게 말해서, 이 두 레이어는 어떻게 구조를 설득할지에 따라 선택한 것이고, 16이라는 숫자는 화면에 맞추기 좋은 좋은 숫자에 불과합니다. 실제로는 특정 구조에 대한 실험에 충분한 공간이 있어요. 네트워크가 작동하는 방식은 하나의 층의 활성화가 다음 층의 활성화를 결정합니다. 그리고 물론 정보 처리 기계로서의 신경망의 핵심은 정확히 그 활성화가 어떻게 하나의 층에서 다음 층으로 활성화를 가져오는지에 달렸습니다. 이는 생물학적 신경 세포의 네트워크에서 일부 세포군의 발화가 정확히 다른 세포군을 일으키는 방식과 비교되도록 약간 헐값지게 되어있어요. 이제 여기서 보여주는 네트워크는 이미 손글씨 숫자를 인식하기 위해 훈련되었고, 이게 어떻게 일이 돌아가는지 보여줄게요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 부분에 대한 번역 및 요약 결과를 저장할 리스트\n",
        "translated_summaries = []\n",
        "\n",
        "# 모든 부분에 대해 번역 및 요약 요청 수행\n",
        "for part in parts:\n",
        "    # 실제 환경에서는 이 부분에 API 요청을 넣어야 합니다.\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages = [\n",
        "        {\"role\" : \"system\", \"content\" : \"너는 유튜브를 영어에서 한국어로 번역하는 번역가이자, 요약을 잘하는 역할을 할꺼야\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"업로드한 파일을 한국어로 변역해줘\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : \"한국어로 번역한 내용을 요약해\"},\n",
        "        {\"role\" : \"assistant\", \"content\" : \"Yes.\"},\n",
        "        {\"role\" : \"user\", \"content\" : part}\n",
        "      ],\n",
        "    )\n",
        "    # 번역 및 요약 결과 저장\n",
        "    translated_summary = response.choices[0].message.content\n",
        "    translated_summaries.append(translated_summary)\n",
        "\n",
        "# 모든 결과를 하나의 문자열로 결합\n",
        "final_result = '\\n\\n'.join(translated_summaries)\n",
        "\n",
        "# 최종 결과 출력\n",
        "print(final_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcjGRvu1V17Z",
        "outputId": "3508c0a3-b31d-45bd-f948-142ed49f22f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이것은 3이다. 서투르게 작성되었으며 28x28 픽셀의 매우 낮은 해상도로 렌더링되었다. \n",
            "\n",
            "하지만 당신의 뇌는 이것을 3으로 인식하는 데 어려움이 없다. 그리고 이것도, 이것도 3으로 인식할 수 있다. \n",
            "\n",
            "매우 다른 각 픽셀의 구체적인 값들에도 불구하고 다음 이미지에서 3으로 인식할 수 있다. \n",
            "\n",
            "이 3을 볼 때 활성화되는 특정한 빛감지 세포들은 이 3을 볼 때 활성화되는 세포들과 매우 다르다. \n",
            "\n",
            "그러나 당신의 믿을 수있는 시각 피질의 어딘가에서 이것을 같은 아이디어로 해석하는 한편, \n",
            "\n",
            "다른 이미지를 독립적인 아이디어로 인식한다. 그러나 '네트워크는 28x28 그리드를 입력으로 받아 \n",
            "\n",
            "0부터 10 사이의 단일 숫자를 출력하는 프로그램을 작성하라고 한다면, \n",
            "\n",
            "이 작업은 한심하게도 어렵게 느껴진다. 돌 덩어리 아래에서 살아 온 것이 아니라면, \n",
            "\n",
            "기계 학습과 신경망의 관련성과 중요성을 설득할 필요가 없을 것 같다. \n",
            "\n",
            "하지만 여기에서 신경망이라는 것이 실제로 무엇인지, 어떤 배경도 없이 설명하고, \n",
            "\n",
            "그 과정을 수학적 개념으로 시각화해 도움을 줄 것이다. \n",
            "\n",
            "그저 구조 자체에 동기부여가 된다는 느낌을 갖기를 바랍니다. 그리고 읽거나 \n",
            "\n",
            "들을 때 '신경망이 학습 한다'는 것이 무슨 의미인지 알게되는 희망입니다. \n",
            "\n",
            "이 비디오는 오로지 구조 구성 요소에 초점을 맞추어, 다음 비디오에서는 학습에 대해 다루게 될 것입니다. \n",
            "\n",
            "우리가할 일은 손으로 쓴 숫자를 인식할 수 있는 신경망을 만드는 것입니다.이는 주제를 소개하는\n",
            "\n",
            "여러 가지 빈티지한 예제 중 하나입니다. 그리고 나는 여기서 처음부터 익숙한 방법을\n",
            "\n",
            "따르기로 결정했습니다. 왜냐하면 이 두 가지 비디오의 끝에서 더 자세히 알아보고,\n",
            "\n",
            "자신의 컴퓨터에서 이를 실행시키고 놀 수 있는 코드를 다운로드할 수 있는 몇 가지\n",
            "\n",
            "좋은 자료를 제시하려고하기 때문입니다. 신경망의 여러 변형이 존재하고, 최근 몇 년 동안\n",
            "\n",
            "이 변형들에 대한 연구가 크게 증가했습니다. 하지만 이 두 가지 입문 비디오에서는 추가적인\n",
            "\n",
            "장식 없이 가장 단순한 형태인 \"바닐라\" 모델만 살펴볼 것입니다. 이는 더 강력한 현대 변종들을 이해하기위한\n",
            "\n",
            "필수적인 선행 과제입니다. 하지만 여전히 우리가 생각할 수 있는 복잡도가 있는 형태입니다.\n",
            "\n",
            "심지어 이 가장 단순한 형태에서도 손으로 쓴 숫자를 인식할 수 있으며, 컴퓨터에게 할 수있는\n",
            "\n",
            "재미있는 일입니다. 동시에 그것이 몇 가지 기대에는 부적합하다는 것을 볼 수 있을 것입니다.\n",
            "\n",
            "신경망이름에서 알 수 있듯이, 신경망은 뇌에서 영감을 받았습니다. 하지만 이를 세분화 해보자. \n",
            "\n",
            "뇌의 뉴런은 무엇이며, 어떤 면에서 함께 연결되어 있을까요? 지금 내가 뉴런을 말할 때, \n",
            "\n",
            "그냥 숫자를 포함하는 것으로 생각하길 바랍니다. 특히 0과 1 사이의 수입니다. 본 집합은 \n",
            "\n",
            "입력 이미지의 각 28x28 픽셀에 해당하는 뉴런으로 시작합니다. 총 784 개의 뉴런입니다. \n",
            "\n",
            "각각은 해당 픽셀의 회색 값을 나타내는 숫자를 보유합니다. 0은 검은색 픽셀을 나타내고, \n",
            "\n",
            "1은 흰색 픽셀을 나타냅니다. 이 뉴런 안의 숫자는 활성화라고 불리며, 뉴런이 높은 숫자의\n",
            "\n",
            "활성화를 가질 때 그 뉴런이 밝아진다고 생각할 수 있는 이미지입니다. \n",
            "\n",
            "그래서 이 784 개의 뉴런은 네트워크의 첫 번째 레이어를 구성합니다. \n",
            "\n",
            "이제 마지막 레이어로 넘어와 보겠습니다. 이 레이어는 10 개의 뉴런을 가지며, \n",
            "\n",
            "각각은 하나의 숫자를 나타냅니다. 이 뉴런의 활성화도 다시 0에서 1 사이의 \n",
            "\n",
            "숫자입니다. 시스템이 주어진 이미지가 특정 숫자와 관련이 있는지 얼마나 많이 \n",
            "\n",
            "생각하는지를 나타냅니다. 이외에도 숨겨진 레이어라고 불리는 몇 개의 레이어가 \n",
            "\n",
            "있는데, 당분간은 어떻게 숫자를 인식하는 이 과정을 처리할 것인지에 대한 큰 \n",
            "\n",
            "의문을 가져야합니다.이 네트워크에서는 두 개의 숨겨진 레이어를 선택했고, \n",
            "\n",
            "각각에 16 개의 뉴런이 있습니다. 솔직히 말해서, 이것은 학습을 동기부여하는\n",
            "\n",
            "방법에 따라 선택한 두 개의 층이며, 16 개는 화면에 표시 할 수있는 좋은 숫자였습니다. \n",
            "\n",
            "실제로 구체적인 구조에 대해 실험이 많이 가능합니다. 네트워크의 작동 방식은 \n",
            "\n",
            "하나의 레이어의 활성화가 다음 레이어의 활성화를 결정하는 것에 달려있습니다. \n",
            "\n",
            "물론 네트워크의 핵심 정보 처리 메커니즘은 한 레이어에서 다음 레이어의 \n",
            "\n",
            "활성화를 어떻게 활성화시키는지에 달려있습니다. 이것은 신경세포의 생물학적 \n",
            "\n",
            "신경망에서 뉴런 그룹이 특정 다른 그룹을 활발하게하는 것과 비슷하게 \n",
            "\n",
            "예상되지 않았나요? 여기에 표시된 네트워크는 이미 손으로 쓴 숫자를 \n",
            "\n",
            "인식하기 위해 훈련되었으며, 그러한 작업 방법을보여줄 수 있습니다.\n",
            "\n",
            "이것은 입력 계층의 784개 뉴런 각각에 대해 이미지의 각 픽셀의 밝기에 따라 활성화가 일어날 때, 그 활성화 패턴은 다음 계층에서 매우 특정한 패턴을 유발하고, 그 다음 계층에서는 일부 패턴을 유발하며, 마지막으로 출력 계층에서 일부 패턴을 준다는 의미입니다. 그리고 해당 출력 계층의 가장 밝은 뉴런은 해당 이미지가 나타내는 숫자에 대한 네트워크의 선택이라고 볼 수 있습니다. 이러한 계층 구조가 지능적으로 작동할 수 있는 이유에 대해 이야기하기 전에, 어떤 기대를 가지고 있는지 알아봅시다. 중간 계층이 무엇을 하는지에 대한 최선의 희망은 무엇인가요?  우리가 숫자를 인식할 때 우리는 여러 구성 요소들을 결합시킵니다. 9는 위쪽에 루프와 오른쪽에 선이 있습니다. 8도 위쪽에 루프가 있지만 아래쪽에 또 다른 루프가 있습니다. 4는 기본적으로 세 개의 선으로 분해되며, 이와 같은 원리입니다. 이상적인 세계에서는, 마지막에서 두 번째 계층의 각 뉴런이 이러한 하위 구성 요소 중 하나에 해당한다고 기대할 수 있습니다. 예를 들어, 위쪽에 루프가 있는 이미지를 입력한다면, 9나 8과 관련된 특정한 뉴런의 활성화값이 1에 가까울 것입니다. 그리고 이 특정한 루프의 픽셀 그룹에 대해 이야기하는 것이 아닙니다. 희망은 일반적인 루프 모양이 어느 정도라도 이 뉴런을 활성화시킨다는 것입니다. 이렇게 하면 세 번째 계층에서 마지막 계층으로 넘어가는 것은 단지 어떤 하위 구성 요소의 조합이 어떤 숫자에 해당하는지를 학습하는 것만 필요합니다. 물론, 이는 문제를 미루는 것입니다. 어떻게 하위 구성 요소를 인식하거나 올바른 하위 구성 요소를 배울 수 있을까요? 그리고 아직은 한 계층이 다음 계층을 어떻게 영향하는지에 대해 얘기하지 않았습니다. \n",
            "\n",
            "루프를 인식하는 것은 하위 문제로 분해될 수도 있습니다. 이를 수행하는 합리적인 방법 중 하나는 첫 번째로 루프를 구성하는 여러 작은 엣지를 먼저 인식하는 것입니다. 마찬가지로, 1, 4 또는 7의 숫자에서 볼 수 있는 긴 선은 실제로는 그냥 긴 엣지입니다. 또는 여러 작은 엣지의 특정한 패턴으로 생각할 수도 있습니다. 그래서 우리의 희망은 네트워크의 두 번째 계층의 각 뉴런이 관련된 작은 엣지들과 관련되어 있다고 할 수 있습니다. 이런 이미지가 입력으로 들어오면, 해당 이미지와 관련된 8~10개의 특정 작은 엣지에 해당하는 모든 뉴런이 활성화되며, 이는 상단 루프와 긴 세로 선에 해당하는 뉴런을 활성화시키고, 이러한 것이 9에 해당하는 뉴런을 활성화시킵니다. 이것이 우리의 최종 네트워크가 실제로 하는 것인지에 대한 다른 질문입니다. 네트워크를 훈련시키는 방법을 알게 되면 이에 대해 다시 언급하겠습니다. 하지만 이것은 우리가 가질 수 있는 희망이고, 이와 같은 계층 구조의 목표입니다. 또한 엣지와 패턴을 인식하는 능력은 이미지 인식 작업에서 매우 유용할 수 있다는 것을 상상할 수 있습니다. 이미지 인식을 넘어서, 계층적 추상화로 분해될 수 있는 모든 지능적인 작업을 수행하고 싶을 수도 있습니다. 음성을 분석하는 것은 원시 오디오를 구분되는 소리로 선택하고, 이들이 특정 음절을 만들기 위해 결합하고, 이들이 단어를 형성하고, 이들이 구문과 더 추상적인 생각을 만들 수 있습니다. 그러나 모든 이런 것들이 실제로 어떻게 작동하는 것인지로 돌아가기 전에, 지금은 하나의 계층에서 다음 계층의 활성화가 어떻게 결정되는지에 대해서 상상해보세요. 목표는 픽셀을 엣지로, 엣지를 패턴으로, 패턴을 숫자로 결합할 수 있는 메커니즘을 가지고 있어야 한다는 것입니다. 매우 구체적인 예로, 두 번째 계층의 특정한 뉴런이 이 영역에 엣지가 있는지 인식하는 것을 희망한다고 가정해 봅시다. 달리해야 할 문제는 네트워크가 어떤 매개변수를 가져야 하는지입니다. 픽셀 패턴이나 이 영역과 관련된 패턴, 또는 여러 엣지가 루프를 형성하는 패턴과 같은 다른 패턴을 포착하기에 충분히 표현력이 있도록 조절할 수 있는 다이얼과 조절기는 무엇일까요? 우리가 해야 할 일은 두 번째 계층의 뉴런과 첫 번째 계층의 뉴런들 사이의 연결 각각에 가중치를 할당하는 것입니다. 이러한 가중치는 단순히 숫자입니다. 그런 다음 첫 번째 계층의 모든 활성화 값을 이러한 가중치에 따라 가중 합산합니다. 나는 이러한 가중치를 단일 그리드로 정리된다고 생각하는 것이 도움이 되고, 나는 이러한 가중치의 값을 표현하는 데에는 밝기를 사용한 초록색 픽셀과 음수 가중치를 나타내기 위해 빨간색 픽셀을 사용합니다. 거의 모든 픽셀에 대한 가중치가 0이고, 우리가 신경 쓰는 이 영역에서 몇 개의 양수 가중치가 있는 경우, 모든 픽셀 값의 가중 합을 취하는 것은 정말로 그 영역의 픽셀 값만 더하는 것에 해당합니다. (번역 중 단어수 초과)\n",
            "\n",
            "우리가 신경쓰는 부분이 있어요. 그리고 만약 여기에 어떤 차이가 있는지 알고 싶다면, 주변 픽셀과 연관된 음의 가중치를 가지고 있는 것이 좋을 것입니다. 그런 다음 가중 합은 중간 픽셀이 밝지만 주변 픽셀은 더 어둡다면 가장 큰 값을 가질 것입니다.\n",
            "\n",
            "이렇게 가중 합을 계산할 때 어떤 수가 나올 수 있지만, 이 네트워크에서는 활성화를 0과 1 사이의 값으로 원합니다. 그래서 일반적으로 이 가중 합을 0과 1 사이의 범위로 압축하는 함수에 입력으로 추가합니다. 이를 수행하는 일반적인 함수는 시그모이드 함수라고도 하는 로지스틱 곡선입니다. 매우 음수의 입력값은 0에 가깝게 수렴하고, 매우 양수의 입력값은 1에 가깝게 수렴하며, 입력값 0 주변에서 꾸준히 증가합니다. 따라서 여기에서 뉴런의 활성화는 해당 가중 합이 얼마나 양수인지를 측정하는 것입니다. 하지만 아마도 가중 합이 0보다 큰 경우에만 뉴런이 작동하는 것을 원한다면 어떨까요? 아마도 그럴 때만 활성화되기를 원한다면 이 가중 합에 시그모이드 함수를 거치기 전에 추가적인 숫자, 예를 들어 -10과 같은 음수를 더하면됩니다. 이 추가 숫자를 편향(bias)이라고 합니다. 따라서 가중치는 두 번째 레이어에서 어떤 픽셀 패턴을 선택하는지를 알려주고, 편향은 뉴런이 의미 있는 활성화를 시작하기 전에 가중 합이 얼마나 커야하는지를 나타냅니다. 이것은 단지 하나의 뉴런입니다. 이 레이어의 다른 모든 뉴런은 첫 번째 레이어의 모든 784개의 픽셀 뉴런과 연결될 것이고, 각각의 연결은 그 자체의 가중치와 함께 있습니다. 또한, 각각은 가중 합 전에 어떤 편향, 다른 숫자를 더해줍니다. 이것은 생각할 것이 많습니다! 이 숨겨진 레이어의 16개의 뉴런으로, 전체적으로는 784 * 16개의 가중치와 16개의 편향이 있습니다. 그리고 이것은 두 번째 레이어로의 연결에 지나지 않습니다. 다른 레이어 사이의 연결도 가중치와 편향이 많이 있습니다. 결국, 이 네트워크는 거의 13,000개의 총 가중치와 편향을 가지고 있습니다. 이 네트워크가 원하는 방식으로 작동할 수 있도록 이 많은 조절 가능한 부분, 13,000개의 가로막대와 다이얼을 조절하는 것을 '학습'이라고 합니다. 여기에 앉아서 손으로 이 모든 가중치와 편향을 의도적으로 조절하여 두 번째 레이어가 모서리를 포착하도록하고, 세 번째 레이어가 패턴을 포착하도록 하는 상상력은 재미있고 동시에 끔찍한 생각실마리입니다. 저는 개인적으로 이것을 네트워크를 완전한 블랙 박스로 취급하는 것보다 만족스러운 방식으로 생각합니다. 왜냐하면 만약 네트워크가 예상한 대로 작동하지 않을 때, 만약 나 자신이 그 가중치와 편향이 실제로 무엇을 의미하는지에 대해 조금이나마 관계를 맺었다면, 구조를 변경하여 성능을 개선하는 방법을 실험할 출발점이 생기기 때문입니다. 또한, 네트워크가 기대한 대로 작동하지만 그 이유가 예상한 것과 다른 경우, 가중치와 편향이 하는 일을 파헤쳐 가정을 도전하고 가능한 솔루션의 전체 영역을 적시하는 좋은 방법입니다. 그런 근데, 여기서 실제 함수를 내려 쓰기란 약간 번거로울 것 같지 않아요? 그래서 이 연결을 더 압축된 방법으로 나타내는 방법을 보여줄게요. 이렇게 보면, 신경망에 대해 더 많이 알고 싶다면 보게 되는 방식입니다. 한 레이어의 모든 활성화를 벡터로 나열하고, 가중치를 행렬로 나열합니다. 이 행렬의 각 행은 다음 레이어의 특정 뉴런과의 연결을 나타냅니다. 이 말은 이 가중치에 따라 첫 번째 레이어의 활성화들의 가중합을 구하는 것이 우리가 왼쪽에 가지고 있는 행렬 벡터 곱의 항목 중 하나에 해당합니다. 그런 다음 각각의 값을 독립적으로 편향에 더하는 대신, 그 모든 편향을 하나의 벡터로 조직화하여 이전의 행렬 벡터 곱에 전체 벡터를 더합니다. 그런 다음 최종적으로 외부에 시그모이드를 씌워, 결과 벡터 안의 각 구성 요소에 대해 시그모이드 함수를 적용할 것입니다. 이렇게 가중치 행렬과 이 벡터들을 각각의 기호로 나타내면,\n",
            "\n",
            "활성화를 한 레이어에서 다음 레이어로 전이하는 전체 과정은 매우 간결하고 깔끔하게 표현될 수 있습니다. 이로 인해 관련 코드는 간단하고 빠른 장점을 가지게 되는데, 많은 라이브러리들이 행렬 곱셈을 최적화해서 사용하기 때문입니다. 앞서 이 뉴런들은 단순히 숫자를 저장하는 것이라고 말씀드렸는데, 실제로 이 숫자들은 입력된 이미지에 따라 달라지므로, 각 뉴런을 함수라고 생각하는 것이 더 정확합니다. 이 함수는 이전 레이어의 모든 뉴런의 출력을 입력으로 받고, 0부터 1까지의 숫자를 출력합니다. 실제로 전체 네트워크는 784개의 숫자를 입력으로 받아 10개의 숫자를 출력하는 함수입니다. 엄청 복잡한 함수인데, 13,000개의 변수, 즉 가중치와 편향으로 이루어진 패턴을 인식하는데 사용되고, 여러번의 행렬-벡터 곱셈 및 시그모이드 함수가 반복되는 것을 포함합니다. 하지만, 어쨌든 그저 함수일 뿐입니다. 그리고 어떤 면에서 이 복잡한 모습이 안심이 됩니다. 간단하면 정말로 숫자를 인식할 수 있는 도전을 할 수 있을까요? 그리고 이 도전을 어떻게 수행하는 걸까요? 이 네트워크는 데이터를 바탕으로 적절한 가중치와 편향을 어떻게 학습할까요? 다음 동영상에서 이 내용과 이 네트워크가 실제로 어떠한 작업을 수행하는지 더 자세히 알려드리겠습니다. 이제 구독 버튼을 눌러주세요. 하지만 사실 대부분의 사람들은 YouTube에서 실시간 알림을 받지 않는 것 같지 않나요? 솔직하게 말하자면, 본 채널의 콘텐츠를 추천하기 위해 YouTube의 추천 알고리즘에 채널의 콘텐츠를 추천받고 싶다는 신호를 보내는 방법으로 구독해주시기를 바라겠습니다. 계속해서 새로운 내용을 기다려주세요. 이 비디오를 Patreon에서 지원해주시는 모든 분들께 정말 감사드립니다. 이번 여름 동안 확률 시리즈가 조금 밀렸는데, 이 프로젝트 이후에 다시 이어갈 예정입니다. 지원자분들은 그 업데이트를 기다려주시기 바랍니다. 여기서 마무리하면서, 제 옆에는 딥러닝의 이론적인 면에 대해 박사학위를 받으신 이샤 리가 계시는데요. 현재 Amplify Partners라는 벤처 자본 회사에서 일하시는데 이번 비디오에 일부 자금을 제공해주셨습니다. 이샤, 한 가지 언급해볼만한 사항은 이 시그모이드 함수입니다. 제가 알기로 초기에는 신경망에서 이 함수를 사용해서 적절한 가중합을 0과 1 사이의 범위로 압축했다고 들었습니다. 생물학적인 뉴런의 비유를 통해 설명한 것 같아요. 맞습니다. 하지만 최근에는 실제로 시그모이드를 사용하는 신경망은 상대적으로 적습니다. 그렇죠. 좀 오래된 방식이라고 말할 수 있죠? 네, 대신에 relu를 사용하는 것이 훨씬 훈련이 쉬워 보입니다. relu란 rectified linear unit의 약자인가요? 네, a와 0 중에서 큰 값을 취하는 함수입니다. a는 비디오에서 설명한 내용에 따라서 정해지는 값입니다. 이 함수 역시 뉴런의 활성화 여부와 생물학적 유사성에서부터 유도되었습니다. 특정 임계값을 넘으면 항등 함수를, 그렇지 않으면 활성화되지 않아서 0이 됩니다. 어떤식으로 보면 단순화된 함수입니다. 시그모이드를 사용하는 것은 훈련에 도움이 안 되거나 아예 훈련하기 어려웠던 것일까요? 아니면 어느 시점에서 훈련하기 어려워져서 relu를 시도하던 중 우연히 잘 작동되었을까요? 네, 정확히는 relu를 시도하다가 놀랍게도 꽤 괜찮은 결과를 얻었기 때문에 현재까지 다양한 딥러닝 네트워크에서 활발하게 사용하고 있습니다. 네, 감사합니다 이샤. 수고하셨습니다.\n"
          ]
        }
      ]
    }
  ]
}